{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smogseer: A Convolutional LSTM model for forecasting air quality from\n",
    "\n",
    "Sentinel-5P data\n",
    "\n",
    "Taimur Khan [![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==)](https://orcid.org/0000-0001-7833-5474) (Helmholtz Centre for Environmental Research - UFZ, Leipzig University)  \n",
    "July 28, 2024\n",
    "\n",
    "The South Asian Smog denotes a recurring annual occurrence of heightened levels of air pollution marked by elevated levels of air contaminants, reduced visibility, and significant socio-economic impacts. These Extreme Smog Events predominantly occur in the northwestern regions of the Indo-Gangetic Plains (IGP) during the months from November to February. Since 2016, their frequency and pervasiveness have led to their colloquial local reference as “the fifth season”. Inhabitants of cities like Lahore, Amritsar, Faisalabad, Multan, and Delhi experience outbursts of extremely hazardous air quality levels during this period. In the last decade, there has been an increase in air pollution sources while crop residue burning, changing weather patterns, and motor vehicles have greatly contributed to the increased frequency and intensity of heightened smog events. However, forecasting of the Extreme Smog Events in South Asia remains elusive as monitoring efforts can help mobilise timely efforts to mitigate conditions that drive the smog. In this study, I use five-day air constituent data from Sentinel-5P level 2 remote sensing product predict hightened aerosol events using Convolutional Long-Short Term Memory neueral network model. The predictor for heightened smog is the UV (Ultraviolet) Aerosol Index at 340-380 nm. The results show that the Aerosol Index can be forecasted at a five-day interval with a Meas Squared Error of ~0.0018 and a loss of ~0.3995, indicating that while Smogseer can predict heightened smog events, the model can be further improved by incorporating additional data sources and refining the model architecture."
   ],
   "id": "d50939c1-9d32-4440-ad62-1136b5e9f574"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convincing evidence has shown that air pollution is a major environmental risk to health. The World Health Organization (WHO) estimates that 4.2 million premature deaths occur each year due to outdoor air pollution (Majeed et al. ([2024](#ref-majeed2024solving))). In South Asia, air pollution is a major public health concern, with high levels of particulate matter (PM2.5) and other pollutants (Majeed et al. ([2024](#ref-majeed2024solving))). Monitoring air quality is essential for public health and environmental protection. Satellites provide a valuable tool for monitoring air quality, as they can measure pollutants such as methane (CH4), nitrogen dioxide (NO2), sulfur dioxide (SO2), carbon monoxide (CO), Formaldehyde (HCHO), and ozone (O3) from space. Using these variables,the Sentinel-5P product also calculates the Aerosol Index (AI) which is a measure of the amount of aerosols in the atmosphere. The AI is used to monitor air quality and can be used to forecast air quality events such as smog. The aerosol index (AI) is a measure of the amount of aerosols in the atmosphere and is used to monitor air quality. The AI data from the Sentinel-5P satellite is available in near real-time and can be used to monitor air quality (ESA ([2021](#ref-Sentinel))).\n",
    "\n",
    "In this project, we will use a convolutional LSTM neural network to forecast the AI in South Asia. The goal of this project is to develop a model that can accurately predict the AI in the future and help in monitoring air quality. The convolutional LSTM neural network is a class of neural networks that is used for spatio-temporal data (Shi et al. ([2015](#ref-shi2015convolutional))). It combines the spatial information from convolutional layers with the temporal information from LSTM layers. The convolutional LSTM neural network has been shown to be effective for predicting spatio-temporal data such as weather forecasting (Kumar et al. ([2020](#ref-kumar2020convcast))) and anomaly detection (Luo, Liu, and Gao ([2017](#ref-luo2017remembering))).\n",
    "\n",
    "The goal of this project is to develop a model that can accurately forecast the AI in the future and help in monitoring air quality."
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An arbitary study area was chosen which confined to bounding box covering northern regions of South Asia as these regions continuosly experience some of world’s worst air quality (Majeed et al. ([2024](#ref-majeed2024solving))). The bounding box coordinates were:\n",
    "\n",
    "``` python\n",
    "bbox = [68.137207,24.886436,84.836426,34.379713] #WGS84 // lon,lat,lon,lat\n",
    "```\n",
    "\n",
    "For the study area abive, the corresponding Sentinel-5P data was downloaded using the Deep Earth System Data Lab’s [xcube sentinel datatore](https://deepesdl.readthedocs.io/en/latest/datasets/ESDC/) (Brandt ([2023](#ref-Brandt:2023))). The attached notebook titled `deepesdl-S5PL2.ipynb` can be viewed to see how this works. ALternative, the attached script titled `data.py` as a Code Link in this manuscript document can also be used to download the raw data.\n",
    "\n",
    "However, for ease, the downloaded version resulting file can be found on Zenodo (Khan ([2024](#ref-khan2024smogseer))).\n",
    "\n",
    "The **timeperiod** for the study was chosen from **01.01.2019** to **31.12.2023**. The data was downloaded from the Sentinel-5P data store using the Deep Earth System Data Lab’s [xcube sentinel datatore](https://deepesdl.readthedocs.io/en/latest/datasets/ESDC/) (Brandt ([2023](#ref-Brandt:2023))). The data was downloaded in the form of netCDF files which contain the AI data for the study area and time period. The data was then preprocessed and split into training and testing datasets. The training dataset contains the AI data from **01.01.2019** to **31.02.2022** and the testing dataset contains the AI data from **01.01.2023** to **31.12.2023**.\n",
    "\n",
    "The **spatial resolution** of the data is 3.629km x 3.269km per pixel.\n",
    "\n",
    "Here is the resulting dataset:"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 2GB\n",
       "Dimensions:         (time: 366, lat: 291, lon: 512, bnds: 2)\n",
       "Coordinates:\n",
       "  * lat             (lat) float64 2kB 34.36 34.33 34.3 ... 24.97 24.94 24.9\n",
       "  * lon             (lon) float64 4kB 68.15 68.19 68.22 ... 84.75 84.79 84.82\n",
       "  * time            (time) datetime64[ns] 3kB 2019-01-03T12:00:00 ... 2024-01...\n",
       "    time_bnds       (time, bnds) datetime64[ns] 6kB ...\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    AER_AI_340_380  (time, lat, lon) float32 218MB ...\n",
       "    AER_AI_354_388  (time, lat, lon) float32 218MB ...\n",
       "    CH4             (time, lat, lon) float32 218MB ...\n",
       "    CLOUD_FRACTION  (time, lat, lon) float32 218MB ...\n",
       "    CO              (time, lat, lon) float32 218MB ...\n",
       "    HCHO            (time, lat, lon) float32 218MB ...\n",
       "    NO2             (time, lat, lon) float32 218MB ...\n",
       "    O3              (time, lat, lon) float32 218MB ...\n",
       "    SO2             (time, lat, lon) float32 218MB ...\n",
       "Attributes:\n",
       "    Conventions:               CF-1.7\n",
       "    title:                     S5PL2 Data Cube Subset\n",
       "    history:                   [{&#x27;program&#x27;: &#x27;xcube_sh.chunkstore.SentinelHubC...\n",
       "    date_created:              2024-05-02T13:00:01.155492\n",
       "    time_coverage_start:       2019-01-01T00:00:00+00:00\n",
       "    time_coverage_end:         2024-01-05T00:00:00+00:00\n",
       "    time_coverage_duration:    P1830DT0H0M0S\n",
       "    time_coverage_resolution:  P5DT0H0M0S\n",
       "    geospatial_lon_min:        68.137207\n",
       "    geospatial_lat_min:        24.886436\n",
       "    geospatial_lon_max:        84.836426\n",
       "    geospatial_lat_max:        34.37759367382812</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-46cd0393-8957-49be-b4fe-56c1f3fb4fa1' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-46cd0393-8957-49be-b4fe-56c1f3fb4fa1' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 366</li><li><span class='xr-has-index'>lat</span>: 291</li><li><span class='xr-has-index'>lon</span>: 512</li><li><span>bnds</span>: 2</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-1873ddc3-1e8b-4977-8c3a-c6f928de29cc' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1873ddc3-1e8b-4977-8c3a-c6f928de29cc' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>34.36 34.33 34.3 ... 24.94 24.9</div><input id='attrs-383dab27-68de-43e9-bb15-74891a0c4433' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-383dab27-68de-43e9-bb15-74891a0c4433' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9aeeab2e-6dcc-4426-94df-fe82b96dab01' class='xr-var-data-in' type='checkbox'><label for='data-9aeeab2e-6dcc-4426-94df-fe82b96dab01' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>decimal_degrees</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd></dl></div><div class='xr-var-data'><pre>array([34.361286, 34.32867 , 34.296055, ..., 24.967975, 24.935359, 24.902744])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>68.15 68.19 68.22 ... 84.79 84.82</div><input id='attrs-958fbf5b-3f0e-4515-a2f9-7d86dfd5a595' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-958fbf5b-3f0e-4515-a2f9-7d86dfd5a595' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-654d857b-58c7-439e-9705-c1b9cac2e49d' class='xr-var-data-in' type='checkbox'><label for='data-654d857b-58c7-439e-9705-c1b9cac2e49d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>decimal_degrees</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>standard_name :</span></dt><dd>longitude</dd></dl></div><div class='xr-var-data'><pre>array([68.153515, 68.18613 , 68.218746, ..., 84.754887, 84.787503, 84.820118])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2019-01-03T12:00:00 ... 2024-01-...</div><input id='attrs-5041e548-d6bc-4657-991c-c1cc36f6382c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-5041e548-d6bc-4657-991c-c1cc36f6382c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8eb27dc7-b017-4933-85f2-7bc02eb43a8a' class='xr-var-data-in' type='checkbox'><label for='data-8eb27dc7-b017-4933-85f2-7bc02eb43a8a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>bounds :</span></dt><dd>time_bnds</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;2019-01-03T12:00:00.000000000&#x27;, &#x27;2019-01-08T12:00:00.000000000&#x27;,\n",
       "       &#x27;2019-01-13T12:00:00.000000000&#x27;, ..., &#x27;2023-12-23T12:00:00.000000000&#x27;,\n",
       "       &#x27;2023-12-28T12:00:00.000000000&#x27;, &#x27;2024-01-02T12:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>time_bnds</span></div><div class='xr-var-dims'>(time, bnds)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-7d76ea20-1be1-43b1-a5dd-2e3d49a7b55d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-7d76ea20-1be1-43b1-a5dd-2e3d49a7b55d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-11498161-9204-4f06-ae97-6cc1a09b2d43' class='xr-var-data-in' type='checkbox'><label for='data-11498161-9204-4f06-ae97-6cc1a09b2d43' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[732 values with dtype=datetime64[ns]]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-309e9938-c905-46c9-b6a8-d453013628ec' class='xr-section-summary-in' type='checkbox'  checked><label for='section-309e9938-c905-46c9-b6a8-d453013628ec' class='xr-section-summary' >Data variables: <span>(9)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>AER_AI_340_380</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-b2b5e623-d4cb-4808-83ff-800a6273a989' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b2b5e623-d4cb-4808-83ff-800a6273a989' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4752bd83-57e6-461e-b406-60e527070197' class='xr-var-data-in' type='checkbox'><label for='data-4752bd83-57e6-461e-b406-60e527070197' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>sample_type :</span></dt><dd>FLOAT32</dd><dt><span>units :</span></dt><dd>Unitless</dd></dl></div><div class='xr-var-data'><pre>[54531072 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>AER_AI_354_388</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-f8cb86ed-3135-4ac8-b9ce-984e5ba0d93f' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-f8cb86ed-3135-4ac8-b9ce-984e5ba0d93f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5349665e-884e-41d2-9002-28a8ede62bbd' class='xr-var-data-in' type='checkbox'><label for='data-5349665e-884e-41d2-9002-28a8ede62bbd' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>sample_type :</span></dt><dd>FLOAT32</dd><dt><span>units :</span></dt><dd>Unitless</dd></dl></div><div class='xr-var-data'><pre>[54531072 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>CH4</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-37989f4b-9195-4b3a-aa08-e567c6006a07' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-37989f4b-9195-4b3a-aa08-e567c6006a07' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-eb7e8d1c-6bc8-4004-b04f-b813e0a76fc6' class='xr-var-data-in' type='checkbox'><label for='data-eb7e8d1c-6bc8-4004-b04f-b813e0a76fc6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>sample_type :</span></dt><dd>FLOAT32</dd><dt><span>units :</span></dt><dd>parts per billion</dd></dl></div><div class='xr-var-data'><pre>[54531072 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>CLOUD_FRACTION</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-2663f935-8e50-402e-a3cd-051b0069e618' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2663f935-8e50-402e-a3cd-051b0069e618' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-50964084-8518-4d3f-a711-d8c04c089072' class='xr-var-data-in' type='checkbox'><label for='data-50964084-8518-4d3f-a711-d8c04c089072' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>sample_type :</span></dt><dd>FLOAT32</dd><dt><span>units :</span></dt><dd>Unitless</dd></dl></div><div class='xr-var-data'><pre>[54531072 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>CO</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-d30b676d-72b0-4cb2-ace5-eb7a8f245e01' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d30b676d-72b0-4cb2-ace5-eb7a8f245e01' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a19858e5-4ecf-4038-ab08-1bc347fcf4ee' class='xr-var-data-in' type='checkbox'><label for='data-a19858e5-4ecf-4038-ab08-1bc347fcf4ee' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>sample_type :</span></dt><dd>FLOAT32</dd><dt><span>units :</span></dt><dd>mol/m^2</dd></dl></div><div class='xr-var-data'><pre>[54531072 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>HCHO</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-c1116b7f-6a07-45a9-9dbb-9cac356af916' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c1116b7f-6a07-45a9-9dbb-9cac356af916' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2c714e42-cdc3-4503-a1b4-9e09e086148f' class='xr-var-data-in' type='checkbox'><label for='data-2c714e42-cdc3-4503-a1b4-9e09e086148f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>sample_type :</span></dt><dd>FLOAT32</dd><dt><span>units :</span></dt><dd>mol/m^2</dd></dl></div><div class='xr-var-data'><pre>[54531072 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>NO2</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-4abe8004-6a4b-4306-bfa7-7dbf9c709d55' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-4abe8004-6a4b-4306-bfa7-7dbf9c709d55' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-03a38d47-0e19-4394-a5aa-30719575ef35' class='xr-var-data-in' type='checkbox'><label for='data-03a38d47-0e19-4394-a5aa-30719575ef35' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>sample_type :</span></dt><dd>FLOAT32</dd><dt><span>units :</span></dt><dd>mol/m^2</dd></dl></div><div class='xr-var-data'><pre>[54531072 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>O3</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-529d68d9-a42d-4093-a070-d2726bf9e630' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-529d68d9-a42d-4093-a070-d2726bf9e630' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9fd469b8-0214-482b-8f31-8ce0a0b7f019' class='xr-var-data-in' type='checkbox'><label for='data-9fd469b8-0214-482b-8f31-8ce0a0b7f019' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>sample_type :</span></dt><dd>FLOAT32</dd><dt><span>units :</span></dt><dd>mol/m^2</dd></dl></div><div class='xr-var-data'><pre>[54531072 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>SO2</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-d2c1b02c-83a9-445e-a6ac-107f067db34d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d2c1b02c-83a9-445e-a6ac-107f067db34d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a98a39e3-adfb-4a77-b3a9-577064e071a1' class='xr-var-data-in' type='checkbox'><label for='data-a98a39e3-adfb-4a77-b3a9-577064e071a1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>sample_type :</span></dt><dd>FLOAT32</dd><dt><span>units :</span></dt><dd>mol/m^2</dd></dl></div><div class='xr-var-data'><pre>[54531072 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-cc796141-0cb8-4821-bb6b-a5f785657134' class='xr-section-summary-in' type='checkbox'  ><label for='section-cc796141-0cb8-4821-bb6b-a5f785657134' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-deb55384-ff91-4298-8be1-e0609c57e7c5' class='xr-index-data-in' type='checkbox'/><label for='index-deb55384-ff91-4298-8be1-e0609c57e7c5' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([34.361285842773434,  34.32867018066406,  34.29605451855468,\n",
       "        34.26343885644531,  34.23082319433593,  34.19820753222656,\n",
       "        34.16559187011718,  34.13297620800781,  34.10036054589843,\n",
       "        34.06774488378906,\n",
       "       ...\n",
       "        25.19628479003906, 25.163669127929687,  25.13105346582031,\n",
       "       25.098437803710937,  25.06582214160156, 25.033206479492186,\n",
       "        25.00059081738281, 24.967975155273436,  24.93535949316406,\n",
       "       24.902743831054686],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;lat&#x27;, length=291))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-2acaa2b6-62f5-434b-9dc1-6a6592d39ce8' class='xr-index-data-in' type='checkbox'/><label for='index-2acaa2b6-62f5-434b-9dc1-6a6592d39ce8' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ 68.1535148310547, 68.18613049316407, 68.21874615527344,\n",
       "       68.25136181738281,  68.2839774794922, 68.31659314160157,\n",
       "       68.34920880371094, 68.38182446582032,  68.4144401279297,\n",
       "       68.44705579003907,\n",
       "       ...\n",
       "       84.52657720996093, 84.55919287207031, 84.59180853417969,\n",
       "       84.62442419628906, 84.65703985839843, 84.68965552050781,\n",
       "       84.72227118261719, 84.75488684472657, 84.78750250683593,\n",
       "       84.82011816894531],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;lon&#x27;, length=512))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-7ecc1edb-9242-462e-afb5-9339c04f20a9' class='xr-index-data-in' type='checkbox'/><label for='index-7ecc1edb-9242-462e-afb5-9339c04f20a9' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2019-01-03 12:00:00&#x27;, &#x27;2019-01-08 12:00:00&#x27;,\n",
       "               &#x27;2019-01-13 12:00:00&#x27;, &#x27;2019-01-18 12:00:00&#x27;,\n",
       "               &#x27;2019-01-23 12:00:00&#x27;, &#x27;2019-01-28 12:00:00&#x27;,\n",
       "               &#x27;2019-02-02 12:00:00&#x27;, &#x27;2019-02-07 12:00:00&#x27;,\n",
       "               &#x27;2019-02-12 12:00:00&#x27;, &#x27;2019-02-17 12:00:00&#x27;,\n",
       "               ...\n",
       "               &#x27;2023-11-18 12:00:00&#x27;, &#x27;2023-11-23 12:00:00&#x27;,\n",
       "               &#x27;2023-11-28 12:00:00&#x27;, &#x27;2023-12-03 12:00:00&#x27;,\n",
       "               &#x27;2023-12-08 12:00:00&#x27;, &#x27;2023-12-13 12:00:00&#x27;,\n",
       "               &#x27;2023-12-18 12:00:00&#x27;, &#x27;2023-12-23 12:00:00&#x27;,\n",
       "               &#x27;2023-12-28 12:00:00&#x27;, &#x27;2024-01-02 12:00:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=366, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b00d61b2-66f1-4dac-8881-841953f50682' class='xr-section-summary-in' type='checkbox'  ><label for='section-b00d61b2-66f1-4dac-8881-841953f50682' class='xr-section-summary' >Attributes: <span>(12)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Conventions :</span></dt><dd>CF-1.7</dd><dt><span>title :</span></dt><dd>S5PL2 Data Cube Subset</dd><dt><span>history :</span></dt><dd>[{&#x27;program&#x27;: &#x27;xcube_sh.chunkstore.SentinelHubChunkStore&#x27;, &#x27;cube_config&#x27;: {&#x27;dataset_name&#x27;: &#x27;S5PL2&#x27;, &#x27;band_names&#x27;: [&#x27;NO2&#x27;, &#x27;SO2&#x27;, &#x27;O3&#x27;, &#x27;CO&#x27;, &#x27;CH4&#x27;, &#x27;HCHO&#x27;, &#x27;AER_AI_340_380&#x27;, &#x27;AER_AI_354_388&#x27;, &#x27;CLOUD_FRACTION&#x27;], &#x27;band_fill_values&#x27;: None, &#x27;band_sample_types&#x27;: None, &#x27;band_units&#x27;: None, &#x27;tile_size&#x27;: [512, 291], &#x27;bbox&#x27;: [68.137207, 24.886436, 84.836426, 34.37759367382812], &#x27;spatial_res&#x27;: 0.032615662109375, &#x27;crs&#x27;: &#x27;WGS84&#x27;, &#x27;upsampling&#x27;: &#x27;BILINEAR&#x27;, &#x27;downsampling&#x27;: &#x27;NEAREST&#x27;, &#x27;mosaicking_order&#x27;: &#x27;mostRecent&#x27;, &#x27;time_range&#x27;: [&#x27;2019-01-01T00:00:00+00:00&#x27;, &#x27;2023-12-31T00:00:00+00:00&#x27;], &#x27;time_period&#x27;: &#x27;5 days 00:00:00&#x27;, &#x27;time_tolerance&#x27;: None, &#x27;collection_id&#x27;: None, &#x27;four_d&#x27;: False}}]</dd><dt><span>date_created :</span></dt><dd>2024-05-02T13:00:01.155492</dd><dt><span>time_coverage_start :</span></dt><dd>2019-01-01T00:00:00+00:00</dd><dt><span>time_coverage_end :</span></dt><dd>2024-01-05T00:00:00+00:00</dd><dt><span>time_coverage_duration :</span></dt><dd>P1830DT0H0M0S</dd><dt><span>time_coverage_resolution :</span></dt><dd>P5DT0H0M0S</dd><dt><span>geospatial_lon_min :</span></dt><dd>68.137207</dd><dt><span>geospatial_lat_min :</span></dt><dd>24.886436</dd><dt><span>geospatial_lon_max :</span></dt><dd>84.836426</dd><dt><span>geospatial_lat_max :</span></dt><dd>34.37759367382812</dd></dl></div></li></ul></div></div>"
      ]
     }
    }
   ],
   "source": [
    "ds = xr.open_dataset('S5PL2_5D.nc')\n",
    "ds"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Predictor variables (features)\n",
    "\n",
    "The following predictor variables were chose for training the ConvLSTM."
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Methane – CH4"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/map_CH4.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-CH4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Ozone – O3"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/map_O3.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-O3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Sulphur Dioxide – SO2"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/map_SO2.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-SO2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Carbon Monoxide – CO"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/map_CO.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-CO"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Nitrogen Dioxide – NO2"
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/map_NO2.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-NO2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Formaldehyde – HCHO"
   ],
   "id": "cell-18"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/map_HCHO.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-HCHO"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Target variable"
   ],
   "id": "cell-20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Aerosol Index – AI (340-380 nm)"
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/map_aer_ai_340_380.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-aeraimap"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Aerosol Index shows large variability through the year and across years."
   ],
   "id": "cell-23"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/aer_ai_340.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-ai"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ],
   "id": "cell-25"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Convolutional Long Short-Term Memory (ConvLSTM) model is a specialized neural network architecture that integrates the strengths of Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks (LSTMs) (Luo, Liu, and Gao ([2017](#ref-luo2017remembering))). This hybrid model is particularly well-suited for tasks involving spatiotemporal data, where both spatial and temporal dependencies are critical. The primary advantage of ConvLSTM models lies in their ability to simultaneously process and analyze spatial and temporal information, making them more effective for spatiotemporal tasks compared to using separate CNN and LSTM models. ConvLSTM models are used extensively in fields such as video processing, weather forecasting, and environmental monitoring, where data exhibits strong correlations across both space and time."
   ],
   "id": "cell-26"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/convlstm.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-convlst"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to use the [predictor variables](#predictor-variables-features) as input to the ConvLSTM and to get the [taget variable](#target-variable) as an output.The model was trained at 50 and 100 epochs. The model was trained using the Adam optimizer with a learning rate of 0.001 and a batch size of 32.\n",
    "\n",
    "I used the numpy (Harris et al. ([2020](#ref-harris2020array))) python package for all the data preprocssing steps and then I used Tensorflow (Martin ([2015](#ref-Martinabadi:2015))) and Keras (Chollet et al. ([2015](#ref-chollet2015keras))) python packages for building a custom ConvLSTM. I used matplotlib (Hunter ([2007](#ref-Hunter:2007))) for all plotting tasks.\n",
    "\n",
    "As model training required a lot of memory, the DeepESDL Jupyter Lab proved to be insufficient. Hence, I had to train the model at the Model Server Grid (MSG) Windows cluster at the Helmholtz - Center for Environmental Research (UFZ) in Leipzig, Germany Even then, the model arichtecture had to be simplified to reduce the memory requirements. The model architecture is as follows:"
   ],
   "id": "cell-28"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/model.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-model"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training took approximately 4 hours for 50 epochs and 10 hours for 100 epochs.\n",
    "\n",
    "The feature training (X_train) dataset dimesion were: (292, 1, 291, 512, 6). Here is the breakdown.\n",
    "\n",
    "    292: dates\n",
    "    1: time step\n",
    "    291: latitudes\n",
    "    512: longitudes\n",
    "    6: Features ['SO2', 'NO2', 'CH4', 'O3', 'CO', 'HCHO']\n",
    "\n",
    "The feature testing ([X_val](data/X_val.npy)) dataset dimesion were: (74, 1, 291, 512, 6). Here is the breakdown.\n",
    "\n",
    "    74: dates\n",
    "    1: time step\n",
    "    291: latitudes\n",
    "    512: longitudes\n",
    "    6: Features ['SO2', 'NO2', 'CH4', 'O3', 'CO', 'HCHO']\n",
    "\n",
    "The target training (y_train) dataset dimension was: (292, 1, 291, 512, 1). Here is the breakdown.\n",
    "\n",
    "    292: dates\n",
    "    1: time step\n",
    "    291: latitudes\n",
    "    512: longitudes\n",
    "    1: Target ['AI']\n",
    "\n",
    "The target testing ([y_val](data/Y_val.npy)) dataset dimension was: (74, 1, 291, 512, 1). Here is the breakdown.\n",
    "\n",
    "    74: dates\n",
    "    1: time step\n",
    "    291: latitudes\n",
    "    512: longitudes\n",
    "    1: Target ['AI']"
   ],
   "id": "cell-30"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Model Workflow\n",
    "\n",
    "Here is a workflow for the provided code in [smogseer.py](src/smogseer.py):\n",
    "\n",
    "> A run of the code can be found in [smogseer50.py](./notebooks/smogseer50-preview.html) and [smogseer100.py](./notebooks/smogseer100-preview.html).\n",
    "\n",
    "-   **Import Libraries**:\n",
    "    -   Import necessary libraries such as `xarray`, `numpy`, `tensorflow`, `sklearn`, and `matplotlib`.\n",
    "-   **Load Dataset**:\n",
    "    -   Load the dataset using `xarray.open_dataset()`.\n",
    "-   **Stack Features**:\n",
    "    -   Stack the features into a single `DataArray` and transpose to desired dimensions.\n",
    "-   **Convert to NumPy Arrays**:\n",
    "    -   Convert the `DataArray` to a NumPy array.\n",
    "-   **Normalize Input Data**:\n",
    "    -   Normalize the input data using `StandardScaler`.\n",
    "-   **Impute Missing Values in Input Data**:\n",
    "    -   Reshape the data for imputation.\n",
    "    -   Impute missing values using `SimpleImputer`.\n",
    "    -   Reshape the data back to original dimensions.\n",
    "-   **Add Time Dimension to Input Data**:\n",
    "    -   Add an additional time dimension to the input data.\n",
    "-   **Load Target Data**:\n",
    "    -   Load the target dataset using `xarray.open_dataset()`.\n",
    "-   **Normalize Target Data**:\n",
    "    -   Normalize the target data using `MinMaxScaler`.\n",
    "-   **Impute Missing Values in Target Data**:\n",
    "    -   Reshape the target data for imputation.\n",
    "    -   Impute missing values using `SimpleImputer`.\n",
    "    -   Reshape the target data back to original dimensions.\n",
    "-   **Ensure Target Data Shape**:\n",
    "    -   Ensure the target data shape is `(num_samples, num_timesteps, num_latitudes, num_longitudes, 1)`.\n",
    "-   **Remove Samples with NaN Values**:\n",
    "    -   Identify and remove samples with NaN values in the target data.\n",
    "-   **Verify Target Data Range**:\n",
    "    -   Ensure the target data values are within the valid range `[0, 1]`.\n",
    "-   **Split Data into Training and Validation Sets**:\n",
    "    -   Split the cleaned data into training and validation sets based on a defined ratio.\n",
    "-   **Define Model Architecture**:\n",
    "    -   Define the model architecture using `ConvLSTM2D` and `Conv3D` layers with appropriate activation functions and initializers.\n",
    "    -   Add batch normalization layers between LSTM layers.\n",
    "-   **Compile Model**:\n",
    "    -   Compile the model with `Adam` optimizer, `binary_crossentropy` loss, and `mean_square_error` as a metric.\n",
    "-   **Print Model Summary**:\n",
    "    -   Print the summary of the defined model.\n",
    "-   **Define Data Generator Class**:\n",
    "    -   Define a `DataGenerator` class to handle large datasets efficiently.\n",
    "-   **Initialize Data Generators**:\n",
    "    -   Initialize training and validation data generators with a specified batch size.\n",
    "-   **Define Callbacks for Training**:\n",
    "    -   Define callbacks for reducing learning rate, early stopping, and TensorBoard logging.\n",
    "-   **Train the Model**:\n",
    "    -   Train the model using the data generators and defined callbacks.\n",
    "-   **Save the Model**:\n",
    "    -   Save the trained model to a keras file .\n",
    "-   **Load the Model**:\n",
    "    -   Load the saved model for further evaluation and prediction.\n",
    "-   **Run Predictions on Validation Data**:\n",
    "    -   Run predictions on the validation data using the loaded model.\n",
    "-   **Evaluate the Model**:\n",
    "    -   Evaluate the model on the validation data to obtain loss and accuracy.\n",
    "-   **Binary Classification Threshold**:\n",
    "    -   Apply a threshold to convert predictions to binary values for classification.\n",
    "-   **Flatten Predictions and Ground Truth**:\n",
    "    -   Flatten the predictions and ground truth data for comparison.\n",
    "-   **Plot Comparisons and Training History**:\n",
    "    -   Define functions to plot comparisons between ground truth and predictions.\n",
    "    -   Visualize a few samples by plotting comparisons.\n",
    "    -   Define a function to plot training and validation loss and accuracy over epochs.\n",
    "    -   Plot and save the training history."
   ],
   "id": "cell-31"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the 50 epoch model and run predictions on the validation data, you can use the following code:\n",
    "\n",
    "``` python\n",
    "## LOAD CHECKPOINTS IF NEEDED\n",
    "X_val = np.load('data/X_val.npy')\n",
    "y_val = np.load('data/Y_val.npy')\n",
    "\n",
    "# Load the model\n",
    "model = load_model('smogseer50.keras')\n",
    "\n",
    "# Run predictions on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "```"
   ],
   "id": "cell-32"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3/3 ━━━━━━━━━━━━━━━━━━━━ 7s 693ms/step\n",
      "3/3 ━━━━━━━━━━━━━━━━━━━━ 3s 432ms/step - loss: 0.3992 - mean_squared_error: 0.0016\n",
      "Validation Loss: 0.39958614110946655\n",
      "Validation Accuracy: 0.0018263210076838732"
     ]
    }
   ],
   "source": [
    "## LOAD CHECKPOINTS IF NEEDED\n",
    "X_val = np.load('X_val.npy')\n",
    "y_val = np.load('Y_val.npy')\n",
    "\n",
    "# Load the model\n",
    "model = load_model('smogseer50.keras')\n",
    "\n",
    "# Run predictions on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ],
   "id": "cell-33"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the 100 epoch model and run predictions on the validation data, you can use the following code:\n",
    "\n",
    "``` python\n",
    "## LOAD CHECKPOINTS IF NEEDED\n",
    "X_val = np.load('data/X_val.npy')\n",
    "y_val = np.load('data/Y_val.npy')\n",
    "\n",
    "# Load the model\n",
    "model = load_model('smogseer100.keras')\n",
    "\n",
    "# Run predictions on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "```"
   ],
   "id": "cell-34"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3/3 ━━━━━━━━━━━━━━━━━━━━ 3s 632ms/step\n",
      "3/3 ━━━━━━━━━━━━━━━━━━━━ 3s 423ms/step - loss: 0.4003 - mean_squared_error: 0.0019\n",
      "Validation Loss: 0.40102294087409973\n",
      "Validation Accuracy: 0.0022550118155777454"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model('smogseer100.keras')\n",
    "\n",
    "# Run predictions on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ],
   "id": "cell-35"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images were converted to a GIF. The ground truth for the same time period was also visualised. The GIFs can be see side by side here:"
   ],
   "id": "cell-36"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/comparison_plot_1.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-comparison"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model prediction and gorund truth data were visualised side by side for 5 timesteps, which is 25 days. These images can be found in the `static` folder in the repository.\n",
    "\n",
    "An example:"
   ],
   "id": "cell-38"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"static/comparison.gif\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-gif"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ],
   "id": "cell-40"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metrics used in Smogseer are: 1. Binary Crossentropy Loss, 2. Mean Squared Error.\n",
    "\n",
    "Here is what the evaluation metrics look like for the 50 epochs model:"
   ],
   "id": "cell-41"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/training_history_epoch50.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-smogseer50"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is what the evaluation metrics look like for the 100 epochs model:"
   ],
   "id": "cell-43"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "image_path = \"static/training_history_epoch100.png\"\n",
    "Image(filename=image_path)"
   ],
   "id": "cell-fig-smogseer100"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion"
   ],
   "id": "cell-45"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Loss over Epochs\n",
    "\n",
    "**Training Loss (Blue Line):**\n",
    "\n",
    "-   The training loss starts at around 0.70 and decreases steadily as the number of epochs increases.\n",
    "-   It shows a continuous decline, indicating that the model is learning from the training data and improving its performance.\n",
    "\n",
    "**Validation Loss (Orange Line):**\n",
    "\n",
    "-   The validation loss starts slightly higher than the training loss, which is typical.\n",
    "-   It follows a similar declining trend as the training loss.\n",
    "-   The validation loss closely tracks the training loss, which suggests that the model is generalizing well to the validation data without overfitting.\n",
    "\n",
    "## 5.2 MSE over Epochs\n",
    "\n",
    "**Training MSE (Blue Line):**\n",
    "\n",
    "-   The training MSE starts at a high value and decreases steadily, similar to the training loss.\n",
    "-   This decrease indicates that the model’s predictions are becoming closer to the actual target values as training progresses.\n",
    "\n",
    "**Validation MSE (Orange Line):**\n",
    "\n",
    "-   The validation MSE also starts high and decreases over the epochs.\n",
    "-   It tracks the training MSE closely, reinforcing that the model’s performance on unseen data is improving without significant overfitting.\n",
    "\n",
    "## 5.3 Key Observations\n",
    "\n",
    "-   Steady Decrease: Both the loss and MSE for training and validation datasets are steadily decreasing, which is a positive sign that the model is learning effectively.\n",
    "-   No Overfitting: Since the validation loss and MSE closely follow the training loss and MSE without diverging, it indicates that there is no significant overfitting.\n",
    "-   Plateauing: Both training and validation loss/MSE curves start to plateau after about 30 epochs. This suggests that further training may not significantly improve the model’s performance.\n",
    "\n",
    "## 5.4 Recommendations\n",
    "\n",
    "-   Early Stopping: Implement early stopping in future training runs to stop training when the validation loss stops improving, saving computational resources and potentially preventing overfitting.\n",
    "-   Learning Rate: If you observe the model’s performance plateauing, consider decreasing the learning rate to allow for finer adjustments to the weights.\n",
    "-   Model architecture: Experiment with different model architectures, hyperparameters, or additional features to improve the model’s predictive performance."
   ],
   "id": "cell-46"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. References\n",
    "\n",
    "Brandt, Alicja AND Fomferra, Gunnar AND Balfanz. 2023. “DeepESDL-an Open Platform for Research and Collaboration in Earth Sciences.” In *EGU General Assembly Conference Abstracts*, EGU–15225.\n",
    "\n",
    "Chollet, François et al. 2015. “Keras.” <https://keras.io>.\n",
    "\n",
    "ESA. 2021. “Copernicus Sentinel-5P (Processed by ESA), TROPOMI Level 2 Nitrogen Dioxide Total Column Products.” <https://doi.org/10.5270/S5P-9bnp8q8>.\n",
    "\n",
    "Harris, Charles R., K. Jarrod Millman, Stéfan J. van der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020. “Array Programming with NumPy.” *Nature* 585 (7825): 357–62. <https://doi.org/10.1038/s41586-020-2649-2>.\n",
    "\n",
    "Hunter, J. D. 2007. “Matplotlib: A 2D Graphics Environment.” *Computing in Science & Engineering* 9 (3): 90–95. <https://doi.org/10.1109/MCSE.2007.55>.\n",
    "\n",
    "Khan, Taimur. 2024. “Smogseer: A Convolutional LSTM for Forecasting Air Quality Metrics from Sentinel-5P Data.” <https://doi.org/10.5281/zenodo.13118498>.\n",
    "\n",
    "Kumar, Ashutosh, Tanvir Islam, Yoshihide Sekimoto, Chris Mattmann, and Brian Wilson. 2020. “Convcast: An Embedded Convolutional LSTM Based Architecture for Precipitation Nowcasting Using Satellite Data.” *Plos One* 15 (3): e0230114.\n",
    "\n",
    "Luo, Weixin, Wen Liu, and Shenghua Gao. 2017. “Remembering History with Convolutional Lstm for Anomaly Detection.” In *2017 IEEE International Conference on Multimedia and Expo (ICME)*, 439–44. IEEE.\n",
    "\n",
    "Majeed, Rabia, Muhammad Shehzaib Anjum, Muhammad Imad-ud-din, Suhaib Malik, Muhammad Naveed Anwar, Bilal Anwar, and Muhammad Fahim Khokhar. 2024. “Solving the Mysteries of Lahore Smog: The Fifth Season in the Country.” *Frontiers in Sustainable Cities* 5: 1314426.\n",
    "\n",
    "Martin, abadi AND Ashish agarwal AND Paul barham AND Eugene brevdo AND Zhifeng chen AND Craig citro AND Greg s. corrado AND Andy davis AND Jeffrey dean AND Matthieu devin AND Sanjay ghemawat AND Ian goodfellow AND Andrew harp AND Geoffrey irving AND Michael isard AND Yangqing Jia AND Rafal jozefowicz AND Lukasz kaiser AND Manjunath kudlur AND Josh levenberg AND Dandelion mané AND Rajat monga AND Sherry moore AND Derek murray AND Chris olah AND Mike schuster AND Jonathon shlens AND Benoit steiner AND Ilya sutskever AND Kunal talwar AND Paul tucker AND Vincent vanhoucke AND Vijay vasudevan AND Fernanda viégas AND Oriol vinyals AND Pete warden AND Martin wattenberg AND Martin wicke AND Yuan yu AND Xiaoqiang zheng. 2015. “TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems.” <https://www.tensorflow.org/>.\n",
    "\n",
    "Shi, Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo. 2015. “Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting.” *Advances in Neural Information Processing Systems* 28."
   ],
   "id": "cell-47"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
